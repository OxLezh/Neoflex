# Курсовой проект для студентов учебного центра Neoflex по направлению «Data-Engineering (BDS)»

# Проектная работа “Реализация процедуры ETL”

## Задание №2

В предыдущем задании вы занимались восстановлением потерянных данных и сломавшегося функционала расчёта витрины 101-й формы в реляционной БД (Oracle / PostgreSQL).

Во время общения с архитектором вы узнаёте, что банк решил мигрировать свой DWH в Hadoop, а ETL-процессы перевести на Spark. В виду этого необходимо настроить среду для исследования возможностей новых инструментов и того как в них можно переложить существующий ETL-функционал.


### Задача 2.2.

Описание задачи в документации.

### <u>Запуск проекта</u>:

Для запуска необходимо:

1. Установить зависимости:

```bash
pip install -r requirements.txt
```
2. Создать в корне файл _.env_ для подключения к СУБД PostgreSQL и вставить (например):

```base
DB_NAME=postgres
DB_HOST=127.0.0.1
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=вашпароль
```
или переименовать файл _env_example.txt_ в _.env_ и внести в него изменения.

### <u>Файлы репозитория</u>:

* _main.py_ - python-cкрипт для запуска программы.

* _Курсовой_проект_DataEngineer_Задача_2.2.md_ - документация по заданию.

* _requirements.txt_ - cписок зависимостей.

* _data_deltas_ - папка c дельтами,которые хранятся в виде вложенных директорий с наименованием в порядке возрастания (1000,1001...).

* _data_out.parquet_ - служебная папка для хранения файлов в формате parquet. Создается при работе приложения.

* _mirr_md_account_d_ - папка, в которой хранится зеркало в формате csv. Создается при работе приложения.

* _1004_ папка с новой дельтой.
